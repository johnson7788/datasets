<p align="center">
    <br>
    <img src="https://raw.githubusercontent.com/huggingface/datasets/master/docs/source/imgs/datasets_logo_name.jpg" width="400"/>
    <br>
<p>
<p align="center">
    <a href="https://circleci.com/gh/huggingface/datasets">
        <img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/datasets/master">
    </a>
    <a href="https://github.com/huggingface/datasets/blob/master/LICENSE">
        <img alt="GitHub" src="https://img.shields.io/github/license/huggingface/datasets.svg?color=blue">
    </a>
    <a href="https://huggingface.co/docs/datasets/index.html">
        <img alt="Documentation" src="https://img.shields.io/website/http/huggingface.co/docs/datasets/index.html.svg?down_color=red&down_message=offline&up_message=online">
    </a>
    <a href="https://github.com/huggingface/datasets/releases">
        <img alt="GitHub release" src="https://img.shields.io/github/release/huggingface/datasets.svg">
    </a>
    <a href="https://huggingface.co/datasets/">
        <img alt="Number of datasets" src="https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/datasets&color=brightgreen">
    </a>
</p>

<h3 align="center">
<p> Datasets and evaluation metrics for natural language processing and more
<p> Compatible with NumPy, Pandas, PyTorch and TensorFlow
</h3>

ğŸ“ **Documentation**: https://huggingface.co/docs/datasets/

ğŸ•¹ **Colab demo**: https://colab.research.google.com/github/huggingface/datasets/blob/master/notebooks/Overview.ipynb

ğŸ” **Online dataset explorer**: https://huggingface.co/datasets/viewer

ğŸ¤—Datasetsæ˜¯ä¸€ä¸ªè½»é‡çº§ä¸”å¯æ‰©å±•çš„åº“ï¼Œå¯è½»æ¾å…±äº«å’Œè®¿é—®ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†(NLP)ç­‰çš„æ•°æ®é›†å’Œè¯„ä¼°æŒ‡æ ‡ã€‚

ğŸ¤—Datasetså…·æœ‰è®¸å¤šæœ‰è¶£çš„ç‰¹å¾(é™¤äº†æ˜“äºå…±äº«å’Œ è®¿é—®æ•°æ®é›†/æŒ‡æ ‡)ï¼š

-ä¸NumPyï¼ŒPandasï¼ŒPyTorchå’ŒTensorflow 2çš„å†…ç½®äº’æ“ä½œæ€§
-è½»å·§ä¸”å¿«é€Ÿçš„é€æ˜å’ŒPythonic API 
-åŠ›æ±‚å¤§ æ•°æ®é›†ï¼šâ€œğŸ¤—Datasetsâ€è‡ªç„¶ä½¿ç”¨æˆ·æ‘†è„±äº†RAMå†…å­˜é™åˆ¶ï¼Œé»˜è®¤æƒ…å†µä¸‹æ‰€æœ‰æ•°æ®é›†éƒ½æ˜ å°„åˆ°é©±åŠ¨å™¨ä¸Šã€‚
-æ™ºèƒ½ç¼“å­˜ï¼šä»ä¸ç­‰å¾…æ•°æ®å¤„ç†å‡ æ¬¡

ğŸ¤—Datasetså½“å‰å¯è®¿é—®çº¦100ä¸ªNLPæ•°æ®é›†å’Œçº¦10ä¸ªè¯„ä¼°æŒ‡æ ‡ï¼Œæ—¨åœ¨è®©ç¤¾åŒºè½»æ¾æ·»åŠ å’Œå…±äº«æ–°çš„æ•°æ®é›†å’Œè¯„ä¼°æŒ‡æ ‡ã€‚
 æ‚¨å¯ä»¥ä½¿ç”¨æ¥æµè§ˆå®Œæ•´çš„æ•°æ®é›†  [live datasets viewer](https://huggingface.co/datasets/viewer).

â€œğŸ¤—Datasetsâ€æºè‡ªä»¤äººæ•¬ç•çš„[`TensorFlow Datasets`](https://github.com/tensorflow/datasets)çš„åˆ†æ”¯ï¼Œ
è€ŒHuggingFaceå›¢é˜Ÿè¦æ·±æ·±æ„Ÿè°¢TensorFlow Datasetså›¢é˜Ÿæ„å»ºäº†è¿™ä¸ªæƒŠäººçš„åº“ã€‚ 
å…³äº[datasets]ä¸`tfds`ä¹‹é—´å·®å¼‚çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§[[[Datasets`ä¸'tfds`ä¹‹é—´çš„ä¸»è¦å·®å¼‚](#main-differences-between-ğŸ¤—Datasetsand tfds)ã€‚** ** 

# Contributors

[![](https://sourcerer.io/fame/thomwolf/huggingface/datasets/images/0)](https://sourcerer.io/fame/thomwolf/huggingface/datasets/links/0)[![](https://sourcerer.io/fame/thomwolf/huggingface/datasets/images/1)](https://sourcerer.io/fame/thomwolf/huggingface/datasets/links/1)[![](https://sourcerer.io/fame/thomwolf/huggingface/datasets/images/2)](https://sourcerer.io/fame/thomwolf/huggingface/datasets/links/2)[![](https://sourcerer.io/fame/thomwolf/huggingface/datasets/images/3)](https://sourcerer.io/fame/thomwolf/huggingface/datasets/links/3)[![](https://sourcerer.io/fame/thomwolf/huggingface/datasets/images/4)](https://sourcerer.io/fame/thomwolf/huggingface/datasets/links/4)[![](https://sourcerer.io/fame/thomwolf/huggingface/datasets/images/5)](https://sourcerer.io/fame/thomwolf/huggingface/datasets/links/5)[![](https://sourcerer.io/fame/thomwolf/huggingface/datasets/images/6)](https://sourcerer.io/fame/thomwolf/huggingface/datasets/links/6)[![](https://sourcerer.io/fame/thomwolf/huggingface/datasets/images/7)](https://sourcerer.io/fame/thomwolf/huggingface/datasets/links/7)

# Installation

ğŸ¤—Datasetså¯ä»¥ä»PyPiå®‰è£…ï¼Œå¿…é¡»å®‰è£…åœ¨è™šæ‹Ÿç¯å¢ƒä¸­(ä¾‹å¦‚ï¼Œvenvæˆ–conda)

```bash
pip install datasets
```

æœ‰å…³å®‰è£…çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æ–‡æ¡£ä¸­çš„å®‰è£…é¡µé¢ã€‚ : https://huggingface.co/docs/datasets/installation.html

## Using with PyTorch/TensorFlow/pandas

å¦‚æœæ‚¨æ‰“ç®—åœ¨PyTorch(1.0 +)ï¼ŒTensorFlow(2.2+)æˆ–pandasä¸­ä½¿ç”¨`ğŸ¤—Datasets`ï¼Œåˆ™è¿˜åº”è¯¥å®‰è£…PyTorchï¼ŒTensorFlowæˆ–pandasã€‚

æœ‰å…³å°†åº“ä¸NumPyï¼Œpandasï¼ŒPyTorchæˆ–TensorFlowä¸€èµ·ä½¿ç”¨çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æ–‡æ¡£ä¸­çš„å¿«é€Ÿæµè§ˆé¡µé¢ï¼šhttps://huggingface.co/docs/datasets/quicktour.html

# Usage

ğŸ¤—Datasetsçš„ä½¿ç”¨éå¸¸ç®€å•ã€‚ ä¸»è¦æ–¹æ³•æ˜¯ï¼š

- `datasets.list_datasets()` åˆ—å‡ºå¯ç”¨çš„æ•°æ®é›† 
- `datasets.load_dataset(dataset_name, **kwargs)` å®ä¾‹åŒ–æ•°æ®é›† 
- `datasets.list_metrics()` åˆ—å‡ºå¯ç”¨æŒ‡æ ‡ 
- `datasets.load_metric(metric_name, **kwargs)` å®ä¾‹åŒ–æŒ‡æ ‡ 

è¿™æ˜¯ä¸€ä¸ªç®€å•çš„æ ·æœ¬ï¼š 

```python
from datasets import list_datasets, load_dataset, list_metrics, load_metric

#æ‰“å°æ‰€æœ‰å¯ç”¨çš„æ•°æ®é›† 
print(list_datasets())

#åŠ è½½æ•°æ®é›†å¹¶æ‰“å°è®­ç»ƒé›†ä¸­çš„ç¬¬ä¸€ä¸ªæ ·æœ¬ 
squad_dataset = load_dataset('squad')
print(squad_dataset['train'][0])

#åˆ—å‡ºæ‰€æœ‰å¯ç”¨æŒ‡æ ‡ 
print(list_metrics())

#åŠ è½½æŒ‡æ ‡ 
squad_metric = load_metric('squad')
```

æœ‰å…³ä½¿ç”¨åº“çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æ–‡æ¡£ä¸­çš„å¿«é€Ÿæµè§ˆé¡µé¢ã€‚: https://huggingface.co/docs/datasets/quicktour.html 
and the specific pages on
- Loading a dataset https://huggingface.co/docs/datasets/loading_datasets.html
- What's in a Dataset: https://huggingface.co/docs/datasets/exploring.html
- Processing data with `ğŸ¤—Datasets`: https://huggingface.co/docs/datasets/processing.html
- Writing your own dataset loading script: https://huggingface.co/docs/datasets/add_dataset.html
- etc

Another introduction to `ğŸ¤—Datasets` is the tutorial on Google Colab here:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/datasets/blob/master/notebooks/Overview.ipynb)

# Main differences between `datasets` and `tfds`

If you are familiar with the great `Tensorflow Datasets`, here are the main differences between `datasets` and `tfds`:
- the scripts in `ğŸ¤—Datasets` are not provided within the library but are queried, downloaded/cached and dynamically loaded upon request
- `ğŸ¤—Datasets` also provides evaluation metrics in a similar fashion to the datasets, i.e. as dynamically installed scripts with a unified API. This gives access to the pair of a benchmark dataset and a benchmark metric for instance for benchmarks like [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) or [GLUE](https://gluebenchmark.com/).
- the backend serialization of `ğŸ¤—Datasets` is based on [Apache Arrow](https://arrow.apache.org/) instead of TF Records and leverage python dataclasses for info and features with some diverging features (we mostly don't do encoding and store the raw data as much as possible in the backend serialization cache).
- the user-facing dataset object of `ğŸ¤—Datasets` is not a `tf.data.Dataset` but a built-in framework-agnostic dataset class with methods inspired by what we like in `tf.data` (like a `map()` method). It basically wraps a memory-mapped Arrow table cache.

# Disclaimers

Similar to TensorFlow Datasets, `ğŸ¤—Datasets` is a utility library that downloads and prepares public datasets. We do not host or distribute these datasets, vouch for their quality or fairness, or claim that you have license to use them. It is your responsibility to determine whether you have permission to use the dataset under the dataset's license.

If you're a dataset owner and wish to update any part of it (description, citation, etc.), or do not want your dataset to be included in this library, please get in touch through a [GitHub issue](https://github.com/huggingface/datasets/issues/new). Thanks for your contribution to the ML community!
